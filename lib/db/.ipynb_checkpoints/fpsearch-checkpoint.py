import pymongo
import pandas as pd
import re
import rpy2
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()

def getFP(trt_id,
          db_col=None,
          ds_inc = None,
          fp_ds=None,
          fp_n =None
         ):
    # Get the fp object first
    FP = db_col.find_one(dict(trt_id=trt_id))

    # the *_lst hold the accessors in a list for use later
    ds_lst = fp_ds.split('.')
    n_lst  = fp_n.split('.')
          
    fmt = 'FP' + "['%s']" * len(ds_lst)
    
    try:
        FP_ds= eval(fmt % tuple(ds_lst))
        FP_n = eval(fmt % tuple(n_lst))
    except:
        print "Failed to extract ds and n from FP"
        return []

    return dict(ds=FP_ds,n=FP_n)

    
def searchHits(trt_id,
               qy_col=None,
               db_col=None,
               ds_inc = None,
               qy_fp_ds='fp.deseq.fp_z1.ch.ds',
               qy_fp_n ='fp.deseq.fp_z1.ch.n',
               db_fp_ds='fp.deseq.fp_z1.ch.ds',
               db_fp_n ='fp.deseq.fp_z1.ch.n',
               n_genes=False,
               dsn_max=0,
               s0=0.5,
               lim=100,
               dbg=False):
    """
    Searches a query trt_id from qy_col collection against a database collection in db_col 
    using fingerprints. The analysis is specific to fingerprints stored in mongodb collections.
    Fingerprints are in the format dict(ds=[list of descriptors], n=length of descriptors). Each 
    element in a collection can contain multiple fingerprints (e.g. generated by different Z-score
    cut-offs for L2FC values).  

    Inputs:
    qy_fp_ds = query fingerprint descriptor accessor in format l1-key.l2-key.l3-key...ds
    qy_fp_n  = query fingerprint size  accessor in format l1-key.l2-key.l3-key...n
    db_fp_ds = db hit fingerprint descriptor accessor in format l1-key.l2-key.l3-key...ds (defaults to qy_fp_ds)
    db_fp_n  = db hit fingerprint size  accessor in format l1-key.l2-key.l3-key...n (defaults to qy_fp_n)
    ds_inc  = only consider these descriptors
    dsn_max = only include profiles with fp.n < dsn_max
    Output:
    pymongo cursor to iterate over hits
    
    """
   
    # Get the fp object first
    FP = qy_col.find_one(dict(trt_id=trt_id))

    # the *_lst hold the accessors in a list for use later
    qy_ds_lst = qy_fp_ds.split('.')
    qy_n_lst  = qy_fp_n.split('.')
    
    if not (db_fp_ds and db_fp_n):
        db_fp_ds = qy_fp_ds
        db_fp_n  = qy_fp_n

    fmt = 'FP' + "['%s']" * len(qy_ds_lst)
   
    try:
        FP_ds= eval(fmt % tuple(qy_ds_lst))
        FP_n = eval(fmt % tuple(qy_n_lst))
    except:
        print "Failed to extract ds and n from FP"
        return []

    if ds_inc:
        FP_ds = list(set(FP_ds).intersection(ds_inc))
        FP_n  = len(FP_ds)
        
    # the size range of FP for hits
    fp_min= int(s0*FP_n)
    fp_max= int(FP_n/s0)

    if dsn_max and dsn_max>0:
        fp_max = dsn_max

    Match1 =  {'$match':
                {db_fp_n:{'$gte':fp_min, '$lte':fp_max},
                 db_fp_ds:{'$in':FP_ds}
                 }
              }
    Proj1  = {'$project': 
              {'jaccard': 
                 {'$let':
                  {'vars': 
                   {'olap': {'$size':{'$setIntersection': ['$%s'% db_fp_ds,FP_ds] }}},
                   'in': {'$divide':['$$olap',
                                     {'$subtract': [{'$add':[FP_n,'$%s'%db_fp_n]},'$$olap'] }]}
                  }
                 },
              '_id':0,
              'trt_id':1
             }
            }


    Agg = [Match1,Proj1]
    Agg.append({'$sort': {'jaccard':-1}})

    if lim:
        Agg.append({'$limit':lim})
    elif s0:
        Agg.append({'$match':{'jaccard':{'$gte':s0}}})

    return db_col.aggregate(Agg,allowDiskUse=True)


def searchHitTgts(trt_id,Tgt=None,ret=None,sv_col=None,**kwargs):
    try:
        R = pd.DataFrame(list(searchHits(trt_id,**kwargs)))
        R = R.merge(Tgt[['target','trt_id']],left_on='trt_id',right_on='trt_id',how='left')
        R.target.fillna('',inplace=True)
    except:
        print "Something went wrong :("
        return

    R['query_id']=trt_id
    R.rename(columns=dict(trt_id='hit_id'),inplace=True)

    if ret=='dict':
        return R.to_dict('records')
    elif sv_col:
        sv_col.insert_many(R.to_dict('records'))
    else:
        return R


def getHitsFP(trt_id,
              qy_col=None,
              db_col=None,
              qy_fp_ds='fp.deseq.fp_z1.ch.ds',
              qy_fp_n ='fp.deseq.fp_z1.ch.n',
              db_fp_ds='fp.deseq.fp_z1.ch.ds',
              db_fp_n ='fp.deseq.fp_z1.ch.n',
              s0=0.5,
              lim=100,
              ret='df',
              dsn_max=None,
              dbg=False
              ):
    """
    Searches a query trt_id from qy_col collection against a database collection in db_col 
    using fingerprints. The analysis is specific to fingerprints stored in mongodb collections.
    Fingerprints are in the format dict(ds=[list of descriptors], n=length of descriptors). Each 
    element in a collection can contain multiple fingerprints (e.g. generated by different Z-score
    cut-offs for L2FC values). Uses searchHits to find the hits and then returns the dataframe 
    or list containing containing the full vectors for each hits. 

    It assumes that the fp accessors for up and down genes are as follows:
    up   = db_fp_ds.replace('ch','up')
    down = db_fp_ds.replace('ch','down')

    Inputs:
    qy_fp_ds = query fingerprint descriptor accessor in format l1-key.l2-key.l3-key...ds
    qy_fp_n  = query fingerprint size  accessor in format l1-key.l2-key.l3-key...n
    db_fp_ds = db hit fingerprint descriptor accessor in format l1-key.l2-key.l3-key...ds (defaults to qy_fp_ds)
    db_fp_n  = db hit fingerprint size  accessor in format l1-key.l2-key.l3-key...n (defaults to qy_fp_n)
    
    Output:
    List or dataframe of hits along with gene vectors in the appropriate direction
    """
        
    # Get the fp object first
    FP = qy_col.find_one(dict(trt_id=trt_id))

    # the *_lst hold the accessors in a list for use later
    qy_ds_lst = qy_fp_ds.split('.')
    qy_n_lst  = qy_fp_n.split('.')
    
    if not (db_fp_ds and db_fp_n):
        pass
        #db_ds_lst = db_fp_ds.split('.')
        #db_n_lst  = db_fp_n.split('.')
    else:
        #db_fp_ds = qy_fp_ds
        #db_fp_n  = qy_fp_n
        db_ds_lst = qy_ds_lst
        db_n_lst  = qy_n_lst
        
    # Find up and down accessors
    db_fp_ds_up = db_fp_ds.replace('ch','up')
    db_fp_ds_dn = db_fp_ds.replace('ch','dn')


    fmt = 'FP' + "['%s']" * len(qy_ds_lst)
    
    try:
        FP_ds= eval(fmt % tuple(qy_ds_lst))
        FP_n = eval(fmt % tuple(qy_n_lst))
    except:
        print "Failed to extract ds and n from FP"
        return []


    # the size range of FP for hits
    fp_min= int(s0*FP_n)
    fp_max= int(FP_n/s0)

    if dsn_max:
        if dsn_max<fp_max:
            fp_max=dsn_max
            
    Match1 =  {'$match':
                {db_fp_n:{'$gte':fp_min, '$lte':fp_max},
                 db_fp_ds:{'$in':FP_ds}
                 }
              }

    Proj1  = {'$project': 
              {'jaccard': 
                 {'$let':
                  {'vars': 
                   {'olap': {'$size':{'$setIntersection': ['$%s'% db_fp_ds,FP_ds] }}},
                   'in': {'$divide':['$$olap',
                                     {'$subtract': [{'$add':[FP_n,'$%s'%db_fp_n]},'$$olap'] }]}
                  }
                 },
               'gup': 
                 {'$let':
                  {'vars': 
                   {'x': {'$setIntersection': ['$%s'% db_fp_ds_up,FP_ds] }},
                   'in': '$$x'
                  }
                 },
               'gdn': 
                 {'$let':
                  {'vars': 
                   {'x': {'$setIntersection': ['$%s'% db_fp_ds_dn,FP_ds] }},
                   'in': '$$x'
                  }
                 },

              '_id':0,
              'dsstox_cid':1,
              'casrn':1,
              'name':1,
              'chem':1,
              'trt_id':1
             }
            }


    Agg = [Match1,Proj1]
    Agg.append({'$sort': {'jaccard':-1}})

    if lim:
        Agg.append({'$limit':lim})
    elif s0:
        Agg.append({'$match':{'jaccard':{'$gte':s0}}})
        

    R1=[]
    for X in db_col.aggregate(Agg,allowDiskUse=True):
        Up=X.pop('gup')
        Dn=X.pop('gdn')
        H = X
        H.update({g:-1 for g in Dn})
        H.update({g:1 for g in Up})
        R1.append(H)
        
    if len(R1)==0: return pd.DataFrame()

    if ret == 'df':
        R2 = (pd.DataFrame(R1)
                .set_index(['trt_id'])
                .fillna(0))
        R2['qy_fp_ds'] = re.sub('^fp.|.ds$','',qy_fp_ds)
        R2['db_fp_ds'] = re.sub('^fp.|.ds$','',db_fp_ds)               
        R2['qy_trt_id']= trt_id
        C1 = R2.columns.intersection(['dsstox_cid','jaccard','casrn','name','chem','qy_fp_ds','db_fp_ds','qy_trt_id'])
        return R2[C1],R2.drop(C1,axis=1)
    else:
        return R1


x="""
library(gCMAP)

getCMapScore <- function(M_db,z=1){
    M0 <- as.matrix(M_db)
    Z0 <- induceCMAPCollection(M0,'z',lower=-z,higher=z)
    assayDataElement(Z0,'z') <- M0
    cmapTable(connectivity_score(Z0[,1], Z0, element="z"))
}
"""
getCMapScore = robjects.r(x)

x="""
library(gCMAP)

getJGScore <- function(M_db,z=1){
    M0 <- as.matrix(M_db)
    Z0 <- induceCMAPCollection(M0,'z',lower=-z,higher=z)
    assayDataElement(Z0,'z') <- M0
    cmapTable(gsealm_jg_score(Z0[,1], Z0, element="z"))
}
"""
getJGScore = robjects.r(x)    


def searchCMapConn(trt_id,
                   Tgt=None,
                   save=False,
                   sv_col=None,
                   **kwargs
                   ):
    qy_col = kwargs.get('qy_col')
    Q = qy_col.find_one(dict(trt_id=trt_id))
    R = {k:Q.get(k) for k in ['timeh', 'conc', 'name', 'trt_id', 'dsstox_sid', 'media'] if Q.has_key(k)}
    #R.update(dict(nrm=nrm,fp_ds=,de=de))    
    Hits_info,Hits = getHitsFP(trt_id,ret='df',**kwargs)
    if Hits.shape[0]==0: return

    R['nhits']=Hits.shape[0]
    
    Cor = Hits.T.corr(method='spearman')[[trt_id]].rename(columns={trt_id:'sim'}).reset_index()
    #HR  = Cor.merge(Tgt,left_on='trt_id',right_on='trt_id').sort_values('sim',ascending=False)
    HR = Cor.copy()
    HR = HR[HR.trt_id != trt_id]
    HR['q_trt_id']=trt_id
    HR.rename(columns=dict(trt_id='h_trt_id'),inplace=True)
    R['corr']=HR.to_dict('records')

    #X=pandas2ri.py2ri(Hits.T)
    #JG1 = getJGScore(X)
    #JG2 = pandas2ri.ri2py_dataframe(JG1)
    #R['jg']  =JG2.to_dict('records')    

    
    if save and sv_col:
        sv_col.insert_one(R)
    else:
        return HR#,JG2

def searchBSPCMapConn(trt_id,
                   Tgt=None,
                   save=False,
                   sv_col=None,
                   **kwargs
                   ):
    qy_col = kwargs.get('qy_col')
    Q = qy_col.find_one(dict(trt_id=trt_id))
    R = {k:Q.get(k) for k in ['timeh', 'conc', 'name', 'trt_id', 'dsstox_sid', 'media'] if Q.has_key(k)}     
    
    Hits_info,Hits = getHitsFP(trt_id,ret='df',**kwargs)
    if Hits.shape[0]==0: return

    R['nhits']=Hits.shape[0]

    # Now add the profile for trt_id
    fp_up_ds = kwargs['qy_fp_ds'].replace('ch','up')
    fp_up_n  = kwargs['qy_fp_n'].replace('ch','up')
    FP_up = getFP(trt_id,fp_ds=fp_up_ds,fp_n=fp_up_n,db_col=kwargs['qy_col'])
    fp_dn_ds = kwargs['qy_fp_ds'].replace('ch','dn')
    fp_dn_n  = kwargs['qy_fp_n'].replace('ch','dn')
    FP_dn = getFP(trt_id,fp_ds=fp_dn_ds,fp_n=fp_dn_n,db_col=kwargs['qy_col'])
    
    X = {}
    X.update({g:-1 for g in FP_dn['ds']})
    X.update({g: 1 for g in FP_up['ds']})
    FP = pd.Series({k:v for k,v in X.iteritems() if k in Hits.columns})
    Hits.loc[trt_id]=FP
    
    Cor = Hits.T.corr(method='spearman')[[trt_id]].rename(columns={trt_id:'sp_cor'}).reset_index()
    #HR  = Cor.merge(Tgt,left_on='trt_id',right_on='trt_id').sort_values('sim',ascending=False)
    HR = Cor.copy()
    HR = HR[HR.trt_id != trt_id]
    HR['q_trt_id']=trt_id
    HR.rename(columns=dict(trt_id='h_trt_id'),inplace=True)
    R['corr']=HR.to_dict('records')

    #X=pandas2ri.py2ri(Hits.T)
    #JG1 = getJGScore(X)
    #JG2 = pandas2ri.ri2py_dataframe(JG1)
    #R['jg']  =JG2.to_dict('records')    

    
    if save and sv_col:
        sv_col.insert_many(HR.to_dict('records'))
    else:
        return HR#,JG2

    
def searchCMapTarget(trt_id,
                     Tgt=None,
                     save=False,
                     sv_col=None,
                     **kwargs
                     ):
    qy_col = kwargs.get('qy_col')
    Q = qy_col.find_one(dict(trt_id=trt_id))
    if not Q: return
    R = {k:Q.get(k) for k in ['timeh', 'conc', 'name', 'trt_id', 'dsstox_sid', 'media'] if Q.has_key(k)}
    #R.update(dict(nrm=nrm,fp_ds=,de=de))    
    Hits_info,Hits = getHitsFP(trt_id,ret='df',**kwargs)
    if Hits.shape[0]==0: return

    Res = Hits.T.corr(method='spearman')[[trt_id]].reset_index().rename(columns={trt_id:'sp_cor'})
    Res = Res.merge(Tgt,left_on='trt_id',right_on='trt_id')
    Res.rename(columns=dict(trt_id='hid'),inplace=True)
    Res['qid']=trt_id
    Res['fp'] =kwargs.get('db_fp_ds').split('.')[0]
    #X=pandas2ri.py2ri(Hits.T)
    #CM1 = getCMapScore(X)
    #CM2 = (pandas2ri.ri2py_dataframe(CM1)
    #       .merge(Tgt,left_on='set',right_on='trt_id'))
    #CM2 = pandas2ri.ri2py_dataframe(CM1)
    
    #R['cmap']=CM2.to_dict('records')
    
    #JG1 = getJGScore(X)
    #JG2 = pandas2ri.ri2py_dataframe(JG1)
    #       .merge(Tgt,left_on='set',right_on='pfid'))
    #R['jg']  =JG2.to_dict('records')    

    if save and sv_col:
        sv_col.insert_many(Res.to_dict('records'))
    else:
        return Res

